{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import en_core_web_sm\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"amazon_electronics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5003, 9)\n"
     ]
    }
   ],
   "source": [
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>askerID</th>\n",
       "      <th>questionText</th>\n",
       "      <th>answererID</th>\n",
       "      <th>helpful</th>\n",
       "      <th>answerText</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>sent_score</th>\n",
       "      <th>sent_score_quant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD370KY9I1WK</td>\n",
       "      <td>Good for rabbit ears? I live in a basement apartment and use rabbit ears to get my TV reception, which is poor at best.  I was wondering if this would help me get the weaker channels in better or ...</td>\n",
       "      <td>A1GNC9LPUQ8HTG</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>I purchased this Motorola signal booster for my \"rabbit ears\"-connected LCD tv. Received the Motorola on 1/31 and noticed it did NOT improve the tv's weak signal.  When I called Motorola's tech su...</td>\n",
       "      <td>['purchased', 'motorola', 'signal', 'booster', 'rabbit', 'ear', 'connected', 'lcd', 'tv', 'received', 'motorola', 'noticed', 'improve', 'tv', 'weak', 'signal', 'called', 'motorola', 'tech', 'suppo...</td>\n",
       "      <td>purchased motorola signal booster rabbit ear connected lcd tv received motorola noticed improve tv weak signal called motorola tech support evening told particular model work cable satellite hook ...</td>\n",
       "      <td>0.032676</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD370KY9I1WK</td>\n",
       "      <td>Good for rabbit ears? I live in a basement apartment and use rabbit ears to get my TV reception, which is poor at best.  I was wondering if this would help me get the weaker channels in better or ...</td>\n",
       "      <td>A3NYJZ71CESSP8</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>When an amplifier receives a bad signal all you get is an amplified bad signal. It's main purpose is to boost a (good) signal that has been weakened by long cable runs or too many splitter.</td>\n",
       "      <td>['amplifier', 'receives', 'bad', 'signal', 'get', 'amplified', 'bad', 'signal', 'main', 'purpose', 'boost', 'good', 'signal', 'ha', 'weakened', 'long', 'cable', 'run', 'many', 'splitter']</td>\n",
       "      <td>amplifier receives bad signal get amplified bad signal main purpose boost good signal ha weakened long cable run many splitter</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD370KY9I1WK</td>\n",
       "      <td>Good for rabbit ears? I live in a basement apartment and use rabbit ears to get my TV reception, which is poor at best.  I was wondering if this would help me get the weaker channels in better or ...</td>\n",
       "      <td>A3UD50M7M72150</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>hey, i'm in the same prob here, looking for something to boost my weak signal for my regular tv. I don't use cable, just rabbit ears. Any sugestion which antenna is best or should i go look for bo...</td>\n",
       "      <td>['hey', 'prob', 'looking', 'something', 'boost', 'weak', 'signal', 'regular', 'tv', 'use', 'cable', 'rabbit', 'ear', 'sugestion', 'antenna', 'best', 'go', 'look', 'booster']</td>\n",
       "      <td>hey prob looking something boost weak signal regular tv use cable rabbit ear sugestion antenna best go look booster</td>\n",
       "      <td>0.039464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         askerID  \\\n",
       "0  AMD370KY9I1WK   \n",
       "1  AMD370KY9I1WK   \n",
       "2  AMD370KY9I1WK   \n",
       "\n",
       "                                                                                                                                                                                              questionText  \\\n",
       "0  Good for rabbit ears? I live in a basement apartment and use rabbit ears to get my TV reception, which is poor at best.  I was wondering if this would help me get the weaker channels in better or ...   \n",
       "1  Good for rabbit ears? I live in a basement apartment and use rabbit ears to get my TV reception, which is poor at best.  I was wondering if this would help me get the weaker channels in better or ...   \n",
       "2  Good for rabbit ears? I live in a basement apartment and use rabbit ears to get my TV reception, which is poor at best.  I was wondering if this would help me get the weaker channels in better or ...   \n",
       "\n",
       "       answererID helpful  \\\n",
       "0  A1GNC9LPUQ8HTG  [6, 6]   \n",
       "1  A3NYJZ71CESSP8  [3, 3]   \n",
       "2  A3UD50M7M72150  [1, 1]   \n",
       "\n",
       "                                                                                                                                                                                                answerText  \\\n",
       "0  I purchased this Motorola signal booster for my \"rabbit ears\"-connected LCD tv. Received the Motorola on 1/31 and noticed it did NOT improve the tv's weak signal.  When I called Motorola's tech su...   \n",
       "1            When an amplifier receives a bad signal all you get is an amplified bad signal. It's main purpose is to boost a (good) signal that has been weakened by long cable runs or too many splitter.   \n",
       "2  hey, i'm in the same prob here, looking for something to boost my weak signal for my regular tv. I don't use cable, just rabbit ears. Any sugestion which antenna is best or should i go look for bo...   \n",
       "\n",
       "                                                                                                                                                                                                         8  \\\n",
       "0  ['purchased', 'motorola', 'signal', 'booster', 'rabbit', 'ear', 'connected', 'lcd', 'tv', 'received', 'motorola', 'noticed', 'improve', 'tv', 'weak', 'signal', 'called', 'motorola', 'tech', 'suppo...   \n",
       "1              ['amplifier', 'receives', 'bad', 'signal', 'get', 'amplified', 'bad', 'signal', 'main', 'purpose', 'boost', 'good', 'signal', 'ha', 'weakened', 'long', 'cable', 'run', 'many', 'splitter']   \n",
       "2                            ['hey', 'prob', 'looking', 'something', 'boost', 'weak', 'signal', 'regular', 'tv', 'use', 'cable', 'rabbit', 'ear', 'sugestion', 'antenna', 'best', 'go', 'look', 'booster']   \n",
       "\n",
       "                                                                                                                                                                                                         9  \\\n",
       "0  purchased motorola signal booster rabbit ear connected lcd tv received motorola noticed improve tv weak signal called motorola tech support evening told particular model work cable satellite hook ...   \n",
       "1                                                                           amplifier receives bad signal get amplified bad signal main purpose boost good signal ha weakened long cable run many splitter   \n",
       "2                                                                                      hey prob looking something boost weak signal regular tv use cable rabbit ear sugestion antenna best go look booster   \n",
       "\n",
       "   sent_score  sent_score_quant  \n",
       "0    0.032676                 4  \n",
       "1    0.003088                 2  \n",
       "2    0.039464                 4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.sent_score_quant = df.sent_score_quant.astype(int)\n",
    "df.answerText = df.answerText.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['clean_text'] = df.answerText.apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "\n",
    "# remove numbers\n",
    "df['clean_text'] = df['clean_text'].str.replace(\"[0-9]\", \" \")\n",
    "\n",
    "# remove whitespaces\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x:' '.join(x.split()))\n",
    "\n",
    "df['clean_text'] = df.clean_text.apply(lambda x: ' '.join([i for i in x.split() if i not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['clean_text'] = df['clean_text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# function to lemmatize text\n",
    "def lemmatization(texts):\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output\n",
    "\n",
    "df['clean_text'] = lemmatization(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5003, 100)\n"
     ]
    }
   ],
   "source": [
    "new_X = []\n",
    "for i in range(df.shape[0]):\n",
    "    seq = df.clean_text.iloc[i].split()\n",
    "    new_seq = []\n",
    "    for j in range(max_len):\n",
    "        try:\n",
    "            new_seq.append(seq[j])\n",
    "        except:\n",
    "            new_seq.append(\"__PAD__\")\n",
    "    new_X.append(new_seq)\n",
    "df_text = np.array(new_X)\n",
    "print (df_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine import Layer\n",
    "from keras import initializers, regularizers, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable=True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
    "                               name=\"{}_module\".format(self.name))\n",
    "\n",
    "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default'] #K.squeeze(K.cast(x, tf.string), axis=1)\n",
    "        return result\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELMoEmbedding(x):\n",
    "    elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "    return elmo_model(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELMoEmbedding(x):\n",
    "    elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "    return elmo_model(inputs={\n",
    "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
    "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
    "                      },\n",
    "                      signature=\"tokens\",\n",
    "                      as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "     # Input shape 3D tensor with shape: `(samples, steps, features)`.\n",
    "     # Output shape 2D tensor with shape: `(samples, features)`.\n",
    "\n",
    "    def __init__(self, step_dim,W_regulizer = None,b_regulizer = None,\n",
    "                 W_constraint = None, b_constraint = None,bias = True,**kwargs):\n",
    "        \n",
    "        self.W_regulizer = W_regulizer\n",
    "        self.b_regulizer = b_regulizer\n",
    "        \n",
    "        self.W_constraint = W_constraint\n",
    "        self.b_constraint = b_constraint\n",
    "        \n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.W = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[-1],),\n",
    "                                      initializer= self.init,\n",
    "                                      constraint = self.W_constraint,\n",
    "                                      regularizer = self.W_regulizer)\n",
    "        \n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regulizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "        super(Attention, self).build(input_shape)  \n",
    "\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "      \n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "           \n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "    \n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5003, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create datasets (Only take up to 150 words for memory)\n",
    "#df['clean_text2'] = df['clean_text'].apply(lambda x: x.split())\n",
    "#df_text = df['clean_text'].tolist()\n",
    "#df_text = np.array(df_text, dtype=object)[:, np.newaxis]\n",
    "#print (df_text.shape)\n",
    "#df_label = df['sent_score_quant'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5003, 6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label = keras.utils.to_categorical(df.sent_score_quant.values)\n",
    "df_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'attention_keras'...\n",
      "remote: Enumerating objects: 99, done.\u001b[K\n",
      "remote: Total 99 (delta 0), reused 0 (delta 0), pack-reused 99\u001b[K\n",
      "Unpacking objects: 100% (99/99), done.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/thushv89/attention_keras.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 22:24:16.018298 4508337600 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "lambda_27 (Lambda)           (None, 100, 1024)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 100, 128)          131200    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_4 (SeqSel (None, 100, 128)          8257      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 6)                 76806     \n",
      "=================================================================\n",
      "Total params: 216,263\n",
      "Trainable params: 216,263\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_text = layers.Input(shape=(max_len,), dtype=tf.string)\n",
    "embedding = layers.Lambda(ELMoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
    "\n",
    "dense = layers.TimeDistributed(layers.Dense(128, activation='relu'))(embedding)\n",
    "#attn_layer = AttentionLayer(name='attention_layer')\n",
    "#attn_out, attn_states = attn_layer([dense, dense])\n",
    "\n",
    "attention = SeqSelfAttention(attention_activation='relu')(dense) #Attention(max_len)(dense)\n",
    "dense = layers.Flatten()(attention)\n",
    "pred = layers.Dense(df_label.shape[1], activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "embedding_model = Model(inputs=[input_text], outputs=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "80/80 [==============================] - 284s 4s/step - loss: 11.9475 - acc: 0.2250 - val_loss: 12.8945 - val_acc: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf3c56f60>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df_text[:100], df_label[:100],epochs=1,batch_size=batch_size,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Model(inputs=[input_text], outputs=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = embedding_model.predict(df_text[:100],batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1024)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(df_text[:100], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('elmo_ppm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06964785,  0.49956885,  0.5536779 , ...,  0.20250148,\n",
       "        -0.14449076,  0.29933494],\n",
       "       [-0.1393673 ,  0.3974867 , -0.11697337, ...,  0.11262876,\n",
       "        -0.31328064, -0.12441117],\n",
       "       [ 0.3715643 ,  0.4552157 , -1.0826524 , ..., -0.18569992,\n",
       "         0.07689745, -0.38033748],\n",
       "       ...,\n",
       "       [-0.84628683,  0.15489116, -0.5080668 , ..., -0.5052352 ,\n",
       "        -0.21507479, -0.6429738 ],\n",
       "       [-0.8443383 ,  0.149794  , -0.50770366, ..., -0.29923922,\n",
       "        -0.32143813, -0.7706367 ],\n",
       "       [-0.84252095,  0.14497095, -0.5073981 , ..., -0.1159803 ,\n",
       "        -0.17632908, -0.42306253]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['purchased', 'motorola', 'signal', 'booster', 'rabbit',\n",
       "       'earsconnected', 'lcd', 'tv.', 'received', 'motorola', 'noticed',\n",
       "       'improve', \"tv's\", 'weak', 'signal.', 'called', \"motorola's\",\n",
       "       'tech', 'support', 'evening,', 'told', 'particular', 'model',\n",
       "       'works', 'cable', 'satellite', 'hookups.', 'save', 'money.', 'buy',\n",
       "       'stronger', 'antenna.chris', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__'],\n",
       "      dtype='<U133')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['motorola', 'motorola', 'signal', 'earsconnected', \"motorola's\",\n",
       "       'booster', 'lcd', 'rabbit', 'tech', '__PAD__', 'cable',\n",
       "       'satellite', 'purchased', '__PAD__', 'model', '__PAD__', '__PAD__',\n",
       "       'antenna.chris', '__PAD__', 'evening,', 'support', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', \"tv's\", 'received', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', 'tv.', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', 'stronger', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       'improve', 'weak', 'signal.', 'called', 'works', 'particular',\n",
       "       'told', 'noticed', 'buy', 'hookups.', 'money.', 'save'],\n",
       "      dtype='<U133')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[0][cosine_distances(embedding_df[0])[1].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amplifier', 'receives', 'bad', 'signal', 'get', 'amplified',\n",
       "       'bad', 'signal.', 'main', 'purpose', 'boost', 'good', 'signal',\n",
       "       'weakened', 'long', 'cable', 'runs', 'many', 'splitter.',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__'], dtype='<U133')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amplifier', 'main', '__PAD__', 'receives', '__PAD__', 'boost',\n",
       "       'amplified', 'cable', 'signal', '__PAD__', 'bad', 'purpose', 'bad',\n",
       "       '__PAD__', 'signal.', 'good', 'runs', 'get', 'splitter.',\n",
       "       '__PAD__', '__PAD__', '__PAD__', 'many', '__PAD__', 'signal',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', 'weakened', 'long',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__', '__PAD__',\n",
       "       '__PAD__', '__PAD__', '__PAD__'], dtype='<U133')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[1][cosine_distances(embedding_df[0])[0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
