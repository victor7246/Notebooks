{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers deep embedded clustering (DEC) on face images. The paper is - https://arxiv.org/pdf/1511.06335.pdf\n",
    "\n",
    "The source code is hugely influenced by https://github.com/XifengGuo/DEC-keras/blob/master/DEC.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, UpSampling2D, Lambda, RepeatVector, Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, UpSampling2D, Lambda, RepeatVector, Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.metrics import binary_crossentropy, kullback_leibler_divergence\n",
    "from keras import regularizers\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "images = [np.reshape(i, (64, 64, 1)) for i in data.images]\n",
    "images = np.array(images)\n",
    "print (images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/victor/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(64, 64, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "#x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu',padding='same')(x)\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
    "encoder = Model(input_img, Flatten()(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 1)         577       \n",
      "=================================================================\n",
      "Total params: 185,857\n",
      "Trainable params: 185,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "=================================================================\n",
      "Total params: 74,496\n",
      "Trainable params: 74,496\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringLayer(Layer):\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
    "                 q_ij = 1/(1+dist(x_i, u_j)^2), then normalize it.\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1))\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 40\n",
    "alpha = 1\n",
    "\n",
    "clustering_layer = ClusteringLayer(n_clusters, alpha=alpha, name='clustering')(encoder.output)\n",
    "DEC = Model(inputs=encoder.input, outputs=clustering_layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 40)                2621440   \n",
      "=================================================================\n",
      "Total params: 2,695,936\n",
      "Trainable params: 2,695,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DEC.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    weight = y_pred ** 2 / K.sum(y_pred, axis=0)\n",
    "    y_true = K.transpose(K.transpose(weight) / K.sum(weight, axis=1))\n",
    "    return kullback_leibler_divergence(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC.compile(optimizer=Adam(),loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, data.target, test_size=.2, random_state = 123, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/victor/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 256 samples, validate on 64 samples\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 15s 58ms/step - loss: 1.1936 - val_loss: 0.7448\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6891 - val_loss: 0.6496\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6553 - val_loss: 0.6439\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6461 - val_loss: 0.6396\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 14s 55ms/step - loss: 0.6413 - val_loss: 0.6353\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6372 - val_loss: 0.6312\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 14s 55ms/step - loss: 0.6333 - val_loss: 0.6276\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6312 - val_loss: 0.6266\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 14s 55ms/step - loss: 0.6300 - val_loss: 0.6251\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6290 - val_loss: 0.6244\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6283 - val_loss: 0.6238\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6279 - val_loss: 0.6236\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6277 - val_loss: 0.6233\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6275 - val_loss: 0.6231\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6273 - val_loss: 0.6235\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6278 - val_loss: 0.6231\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6273 - val_loss: 0.6227\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 14s 55ms/step - loss: 0.6271 - val_loss: 0.6227\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6269 - val_loss: 0.6226\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 0.6268 - val_loss: 0.6224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a36efaf98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train, epochs=20, validation_split=.2,callbacks=[EarlyStopping(monitor=\"val_loss\",patience=5,mode='min')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters)\n",
    "km.fit(encoder.predict(X_train))\n",
    "DEC.get_layer('clustering').set_weights([km.cluster_centers_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 64 samples\n",
      "Epoch 1/20\n",
      "256/256 [==============================] - 11s 43ms/step - loss: 0.0292 - val_loss: 3.9175e-05\n",
      "Epoch 2/20\n",
      "256/256 [==============================] - 10s 41ms/step - loss: 1.6673e-05 - val_loss: 1.0243e-05\n",
      "Epoch 3/20\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 6.3949e-06 - val_loss: 5.8846e-06\n",
      "Epoch 4/20\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 4.1779e-06 - val_loss: 4.4609e-06\n",
      "Epoch 5/20\n",
      "256/256 [==============================] - 10s 40ms/step - loss: 3.3700e-06 - val_loss: 3.8590e-06\n",
      "Epoch 6/20\n",
      "256/256 [==============================] - 10s 39ms/step - loss: 2.9491e-06 - val_loss: 3.5351e-06\n",
      "Epoch 7/20\n",
      "256/256 [==============================] - 10s 40ms/step - loss: 2.7928e-06 - val_loss: 3.3137e-06\n",
      "Epoch 8/20\n",
      "256/256 [==============================] - 10s 40ms/step - loss: 2.5809e-06 - val_loss: 3.1293e-06\n",
      "Epoch 9/20\n",
      "256/256 [==============================] - 11s 42ms/step - loss: 2.4892e-06 - val_loss: 2.9969e-06\n",
      "Epoch 10/20\n",
      "256/256 [==============================] - 10s 40ms/step - loss: 2.3364e-06 - val_loss: 2.8520e-06\n",
      "Epoch 11/20\n",
      "256/256 [==============================] - 10s 37ms/step - loss: 2.2216e-06 - val_loss: 2.7108e-06\n",
      "Epoch 12/20\n",
      "256/256 [==============================] - 10s 37ms/step - loss: 2.1004e-06 - val_loss: 2.5753e-06\n",
      "Epoch 13/20\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 2.0372e-06 - val_loss: 2.4425e-06\n",
      "Epoch 14/20\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 1.9179e-06 - val_loss: 2.3085e-06\n",
      "Epoch 15/20\n",
      "256/256 [==============================] - 10s 38ms/step - loss: 1.8022e-06 - val_loss: 2.1854e-06\n",
      "Epoch 16/20\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 1.7134e-06 - val_loss: 2.0744e-06\n",
      "Epoch 17/20\n",
      "256/256 [==============================] - 10s 37ms/step - loss: 1.5986e-06 - val_loss: 1.9465e-06\n",
      "Epoch 18/20\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 1.5315e-06 - val_loss: 1.8251e-06\n",
      "Epoch 19/20\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 1.4336e-06 - val_loss: 1.7216e-06\n",
      "Epoch 20/20\n",
      "256/256 [==============================] - 9s 37ms/step - loss: 1.3554e-06 - val_loss: 1.6125e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a37c2a978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEC.fit(X_train, y_train, epochs=20, validation_split=.2,callbacks=[EarlyStopping(monitor=\"val_loss\",patience=5,mode='min')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpred = DEC.predict(X_test)\n",
    "testpred = testpred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23,  4, 30, 15, 34, 30,  5, 28, 37,  9, 17, 21, 21,  3, 18, 34, 19,\n",
       "       16,  4,  0, 19, 28,  7, 17,  1,  4,  1, 23, 24, 32, 17, 10, 28, 19,\n",
       "       34, 26, 33, 33,  7, 29, 23, 29, 26, 15, 25,  3, 35, 24, 39, 24,  2,\n",
       "       10, 27, 23, 28,  2,  1, 30, 19,  8,  3,  2,  5, 22, 39, 27, 12, 21,\n",
       "       10, 15,  7, 26, 23,  5, 24, 17, 20, 32, 11, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.random.random((10,40))\n",
    "q = K.constant(q)\n",
    "weight = q ** 2 / K.sum(q, axis=0)\n",
    "p = K.transpose(K.transpose(weight) / K.sum(weight, axis=1))\n",
    "print (K.eval(kullback_leibler_divergence(p, q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
