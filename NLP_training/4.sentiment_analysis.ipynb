{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use discuss different techniques of sentiment analysis. \n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [Unsupervised Sentiment Analysis](#sentiment)\n",
    "    * [Vader Sentiment Analyzer](#vader)\n",
    "    * [Evaluating Vader](#evvader)\n",
    "* [Supervised Sentiment Modelling](#supervised)\n",
    "    * [Naive Bayes](#nb)\n",
    "    * [Evaluating Naive Bayes](#evnb)\n",
    "    * [LSTM](#lstm)\n",
    "    * [Evaluating LSTM](#evlstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sentiment'></a>\n",
    "\n",
    "### Unsupervised Sentiment Analysis\n",
    "\n",
    "Sentiment analysis aka. opinion mining, polarity analysis is a technique to understand intent within a text. It is one of the most popular areas in NLP. We first discuss lexicon based sentiment analysis for which we use NLTK Vader sentiment analyzer.\n",
    "\n",
    "<a id='vader'></a>\n",
    "#### Vader Sentiment Analyzer\n",
    "\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. VADER uses a combination of A sentiment lexicon is a list of lexical features (e.g., words) which are generally labelled according to their semantic orientation as either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "pd.options.display.max_colwidth = -1\n",
    "\n",
    "data = pd.read_csv('amazon_reviews_cleaned.csv') #for excel file use read_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>clean_reviewtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 22, 2013</td>\n",
       "      <td>A34A1UP40713F8</td>\n",
       "      <td>B00009W3I4</td>\n",
       "      <td>{'Style:': ' Dryer Vent'}</td>\n",
       "      <td>James. Backus</td>\n",
       "      <td>I like this as a vent as well as something that will keep house warmer in winter.  I sanded it and then painted it the same color as the house.  Looks great.</td>\n",
       "      <td>Great product</td>\n",
       "      <td>1377129600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>like vent well something keep house warm winter sand paint color house look great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 8, 2016</td>\n",
       "      <td>A1AHW6I678O6F2</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>kevin.</td>\n",
       "      <td>good item</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1454889600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 5, 2015</td>\n",
       "      <td>A8R48NKTGCJDQ</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>CDBrannom</td>\n",
       "      <td>Fit my new LG dryer perfectly.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1438732800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fit new lg dryer perfectly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 24, 2015</td>\n",
       "      <td>AR3OHHHW01A8E</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>Calvin E Reames</td>\n",
       "      <td>Good value for electric dryers</td>\n",
       "      <td>Perfect size</td>\n",
       "      <td>1429833600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good value electric dryer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 21, 2015</td>\n",
       "      <td>A2CIEGHZ7L1WWR</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>albert j. kong</td>\n",
       "      <td>Price and delivery was excellent.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1426896000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>price delivery excellent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0  5.0      True      08 22, 2013  A34A1UP40713F8  B00009W3I4   \n",
       "1  5.0      True      02 8, 2016   A1AHW6I678O6F2  B00009W3PA   \n",
       "2  5.0      True      08 5, 2015   A8R48NKTGCJDQ   B00009W3PA   \n",
       "3  5.0      True      04 24, 2015  AR3OHHHW01A8E   B00009W3PA   \n",
       "4  5.0      True      03 21, 2015  A2CIEGHZ7L1WWR  B00009W3PA   \n",
       "\n",
       "                       style     reviewerName  \\\n",
       "0  {'Style:': ' Dryer Vent'}  James. Backus     \n",
       "1  {'Size:': ' 6-Foot'}       kevin.            \n",
       "2  {'Size:': ' 6-Foot'}       CDBrannom         \n",
       "3  {'Size:': ' 6-Foot'}       Calvin E Reames   \n",
       "4  {'Size:': ' 6-Foot'}       albert j. kong    \n",
       "\n",
       "                                                                                                                                                      reviewText  \\\n",
       "0  I like this as a vent as well as something that will keep house warmer in winter.  I sanded it and then painted it the same color as the house.  Looks great.   \n",
       "1  good item                                                                                                                                                       \n",
       "2  Fit my new LG dryer perfectly.                                                                                                                                  \n",
       "3  Good value for electric dryers                                                                                                                                  \n",
       "4  Price and delivery was excellent.                                                                                                                               \n",
       "\n",
       "         summary  unixReviewTime vote image  \\\n",
       "0  Great product  1377129600      NaN  NaN    \n",
       "1  Five Stars     1454889600      NaN  NaN    \n",
       "2  Five Stars     1438732800      NaN  NaN    \n",
       "3  Perfect size   1429833600      NaN  NaN    \n",
       "4  Five Stars     1426896000      NaN  NaN    \n",
       "\n",
       "                                                                    clean_reviewtext  \n",
       "0  like vent well something keep house warm winter sand paint color house look great  \n",
       "1  good item                                                                          \n",
       "2  fit new lg dryer perfectly                                                         \n",
       "3  good value electric dryer                                                          \n",
       "4  price delivery excellent                                                           "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overall column is the sentiment. We convert it into int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.overall = data.overall.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP7KO20b4imzKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data.overall.value_counts(normalize=True).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 70% of the reviews have 5 rating. Let us see how Vader evaluates these reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like vent well something keep house warm winter sand paint color house look great\n"
     ]
    }
   ],
   "source": [
    "sample_positive_review = data[data.overall == 5].clean_reviewtext.iloc[0]\n",
    "print (sample_positive_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.8625, 'neg': 0.0, 'neu': 0.485, 'pos': 0.515}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(sample_positive_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall or compound score is 0.8625, which can be think of as a very positive sentiment. Now let us check some neutral and negative ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect match modidify work\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_neutral_review = data[data.overall == 3].clean_reviewtext.iloc[0]\n",
    "print (sample_neutral_review)\n",
    "\n",
    "sid.polarity_scores(sample_neutral_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "careful NewAir stand product NewAir break within first 4 hour use manufacturer cover item warranty case actually think buy NewAir product think twice NewAir Sales date Fri Nov 14 2014 11 03 subject icemaker return Susan Ferguson hi Susan manufacturer warranty void unit purchase private seller consent sell product reason ask copy receipt upon request warranty claim valid authorize dealer proceed warranty work also list authorize dealer web site customer use stand behind product however item purchase private seller purchaser run risk item use open box refurbish scratch dent one year limited manufacturer warranty valid new item sell authorize online dealer unfortunate see situation however need contact seller item replacement refund great day Mireya Customer Support NewAir 3419 East Chapman Ave 190 Orange CA 92869 Ph 855 963 9247 Em fb facebook com NewAirUSA Twitter NewAirUSA Pinterest pinterest com NewAirUSA Instagram NewAirUSA web make awesome Thu Nov 13 2014 7 59 PM Susan Ferguson write Hello Mireya sorry think manufacturer warranty manufacturer NewAir please explain warranty valid case see anywhere warranty exclusion warranty valid purchase authorize dealer addition consumer would never know authorize dealer company sell product implicitly make authorize sincerely hope NewAir reconsider position stand integrity product ice machine literally use four hour fail quite frankly egregious company negate warranty explicitly state repair replace defective material workmanship one year please let know talk dispute department regard matter look forward response refrain give review product matter resolve thank Susan Ferguson Thu Nov 13 2014 3 10 pm NewAir Sales write hi Susan unfortunately ice maker purchase authorize dealer need contact seller Mehadrin Amazon exist issue unit great day Mireya Customer Support NewAir 3419 East Chapman Ave 190 Orange CA 92869 Ph 855 963 9247 Em fb facebook com NewAirUSA Twitter NewAirUSA Pinterest pinterest com NewAirUSA Instagram NewAirUSA web make awesome Thu Nov 13 2014 12 32 pm Susan Ferguson write hello receive AI 100S icemaker March 2014 use one time within 4 hour cool unit shut good estimate pump still work water get pump cool mechanism plug unit back try hour later cool mechanism never turn since product still warranty hope acquire new unit since particular one essentially never use obviously faulty capacity attach receipt reference purchase gift Amazon Marketplace Thanks much look forward response Susan Ferguson\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'compound': 0.9916, 'neg': 0.051, 'neu': 0.786, 'pos': 0.163}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_negative_review = data[data.overall == 1].clean_reviewtext.iloc[0]\n",
    "print (sample_negative_review)\n",
    "\n",
    "sid.polarity_scores(sample_negative_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would give less 1 star possible DONT buy product ice machine stop work four hour use first time notify New Air state would honor one year warranty authorize dealer sell buy product Amazon never even think would cross check purchase manufacturer NewAir stand product use method get honor warranty 200 piece junk never buy another NewAir product\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'compound': 0.7096, 'neg': 0.035, 'neu': 0.835, 'pos': 0.13}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_negative_review = data[data.overall == 1].clean_reviewtext.iloc[1]\n",
    "print (sample_negative_review)\n",
    "\n",
    "sid.polarity_scores(sample_negative_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see Vader severly fail to detect negative sentiments. It could be due to that, in e-commerce website people often give bad rating because of their bad experience and in the reviews they tend to put more words about their distress. These words may not be present in the lexicons used to built Vader.\n",
    "\n",
    "Under these scenarios supervised methods can perform much better. Before going there, let us classify all our reviews and check for the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(x):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(x)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['clean_reviewtext'])\n",
    "\n",
    "data['real_sentiment_score'] = data.clean_reviewtext.apply(get_sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the sentiment scores are real valued, we quantize these into discrete integers between 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(x):\n",
    "    if x < -0.6 :\n",
    "        return 1\n",
    "    elif x >= -0.6 and x < -0.2:\n",
    "        return 2\n",
    "    elif x >= -0.2 and x < 0.2:\n",
    "        return 3\n",
    "    elif x >= 0.2 and x < 0.6:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['predicted_sentiment'] = data.real_sentiment_score.apply(quantize) #pd.qcut(data.real_sentiment_score, 5, labels=False) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD5CAYAAADcDXXiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h/O3/+MqALixgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.predicted_sentiment.value_counts(normalize=True).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='evvader'></a>\n",
    "\n",
    "#### Evaluating Vader\n",
    "\n",
    "Let us check the overall accuracy. As the actual sentiment labels are not even distributed, F1 score is a better evaluation metric than multi class accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6747359154929577\n",
      "0.19290057104467584\n",
      "[[   0    1    3    0    5]\n",
      " [   0    1    9    1    2]\n",
      " [   0    0    2    5  414]\n",
      " [   0    0    4    3  215]\n",
      " [   1    1   19   59 1527]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "print (accuracy_score(data.overall,data.predicted_sentiment))\n",
    "print (f1_score(data.overall,data.predicted_sentiment,average='macro'))\n",
    "print (confusion_matrix(data.overall,data.predicted_sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe how Vader is skewed towards positive sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='supervised'></a>\n",
    "\n",
    "### Supervised methods for Sentiment Analysis\n",
    "\n",
    "<a id='nb'></a>\n",
    "\n",
    "#### Naive Bayes\n",
    "\n",
    "We will start with a very basic technique Naive Bayes. In machine learning, naïve Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features.\n",
    "\n",
    "<img src=https://uc-r.github.io/public/images/analytics/naive_bayes/naive_bayes_icon.png>\n",
    "\n",
    "In our context, we will take tf-idf vectors are our features and sentiment class as our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(lowercase=True, #this will convert all the tokens into lower case\n",
    "                         stop_words='english', #remove english stopwords from vocabulary. if we need the stopwords this value should be None\n",
    "                         analyzer='word', #tokens should be words. we can also use char for character tokens\n",
    "                         max_features=50000, #maximum vocabulary size to restrict too many features\n",
    "                         min_df = 10,\n",
    "                         max_df = .6\n",
    "                        )\n",
    "\n",
    "tfidf_vectorized_corpus = tfidf_vector.fit_transform(data.clean_reviewtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation, we use cross validation. i.e. train on a part of data and testing on the remaining. We will use 5-fold cross validation. \n",
    "\n",
    "<img src=https://miro.medium.com/max/1710/1*rgba1BIOUys7wQcXcL4U5A.png width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_predicted_nb = cross_val_predict(X=tfidf_vectorized_corpus,y=data.overall,cv=5,estimator=nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment_predicted_nb'] = sentiment_predicted_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='evnb'></a>\n",
    "\n",
    "#### Evaluating Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9757922535211268\n",
      "0.5833512796211996\n",
      "[[   0    0    0    0    9]\n",
      " [   0    0    0    4    9]\n",
      " [   0    0  412    0    9]\n",
      " [   0    0    0  206   16]\n",
      " [   0    0    7    1 1599]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asengup6\\softwares\\anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(data.overall,data.sentiment_predicted_nb))\n",
    "print (f1_score(data.overall,data.sentiment_predicted_nb,average='macro'))\n",
    "print (confusion_matrix(data.overall,data.sentiment_predicted_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is able to almost perfectly classify sentiment classes - 3 , 4 and 5. We will now use some deep learning based model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lstm'></a>\n",
    "\n",
    "#### LSTM for Sentiment Classification\n",
    "\n",
    "Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN (recurrent neural network), capable of learning long-term dependencies. RNNs are useful when we have a sequential data like text. As mentioned in https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "\"Humans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. Your thoughts have persistence.\"\n",
    "\n",
    "LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn.\n",
    "\n",
    "<img src=http://dprogrammer.org/wp-content/uploads/2019/04/RNN-vs-LSTM-vs-GRU-1024x308.png>\n",
    "\n",
    "A typical neural network for text classification looks like - \n",
    "\n",
    "1. An embedding layer to learn embedding for each word in each text\n",
    "2. LSTM/GRU/RNN layer consisting multiple cells to identify hidden semantics for each word given previous words. Bidirectional cells are used to use hidden information from both previous and after words.\n",
    "3. Dense layer to consolidate all the information at the text level\n",
    "4. Output layer (softmax/sigmoid) to get final output\n",
    "\n",
    "The parameters of the model are learned by back propagation algorithm where\n",
    "1. parameter weights are initialized randomly\n",
    "2. Calculate the overall loss\n",
    "3. Calculate gradient for each parameter and update using gradient descent\n",
    "\n",
    "By doing so, we can update all the parameters of the model that minimizes the loss. (mean squared error for regression problem, cross entropy for classification etc.)\n",
    "\n",
    "<img src=https://miro.medium.com/max/1201/1*VymEfQTf30evUczsTBiz4g.png width=400>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before feeding the data into NN, we need to tokenize the data and make all the texts of same length. We pass max_len as the maximum length of the text to be passed in the NN. If a text has < max_len number of words, we pad with blank word. For longer texts we will restrict it to max_len."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 50000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data.clean_reviewtext.values)\n",
    "X = tokenizer.texts_to_sequences(data.clean_reviewtext.values)\n",
    "X = pad_sequences(X,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2272, 100)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  56,   1,  21, 168,  23,\n",
       "        15, 947, 948, 949, 950, 951,  15, 262,  49])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'like vent well something keep house warm winter sand paint color house look great'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.clean_reviewtext.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the padded input, we see 0 padding to make the text of 100 length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100 #dimension of the embedding\n",
    "lstm_out = 196 #dimension of the lstm output \n",
    "n_output = data.overall.nunique() #number of possible outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In neural network we can learn the word embeddings from scratch. However, that increases the runtime which we can skip by using pretrained models like - GloVe or, Word2Vec. As, the pretrained models are trained on large corpus, it is wise to use those embeddings and save lot of time and effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:32, 12254.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt','r',encoding='utf8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    #f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1, embed_dim,input_length = X.shape[1], weights=[embedding_matrix], trainable=False))\n",
    "    model.add(SpatialDropout1D(0.4))\n",
    "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(n_output,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy',f1])\n",
    "    #print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          106400    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               232848    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 985       \n",
      "=================================================================\n",
      "Total params: 340,233\n",
      "Trainable params: 233,833\n",
      "Non-trainable params: 106,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For NN we can not directly call cross_val_predict. We have to iteratively run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(data.overall).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "(1815, 100) (1815, 5) (457, 100) (457, 5)\n",
      "Train on 1815 samples, validate on 457 samples\n",
      "Epoch 1/10\n",
      " - 24s - loss: 0.4414 - accuracy: 0.8683 - f1: 0.4037 - val_loss: 0.3315 - val_accuracy: 0.9409 - val_f1: 0.5102\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.51023, saving model to weights1.hdf5\n",
      "Epoch 2/10\n",
      " - 23s - loss: 0.0789 - accuracy: 0.9868 - f1: 0.5952 - val_loss: 0.3307 - val_accuracy: 0.9409 - val_f1: 0.5118\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.51023 to 0.51177, saving model to weights1.hdf5\n",
      "Epoch 3/10\n",
      " - 19s - loss: 0.0522 - accuracy: 0.9879 - f1: 0.5957 - val_loss: 0.3051 - val_accuracy: 0.9409 - val_f1: 0.5113\n",
      "\n",
      "Epoch 00003: val_f1 did not improve from 0.51177\n",
      "Epoch 4/10\n",
      " - 18s - loss: 0.0487 - accuracy: 0.9884 - f1: 0.5930 - val_loss: 0.3428 - val_accuracy: 0.9344 - val_f1: 0.5109\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.51177\n",
      "Epoch 5/10\n",
      " - 19s - loss: 0.0378 - accuracy: 0.9912 - f1: 0.5948 - val_loss: 0.3332 - val_accuracy: 0.9365 - val_f1: 0.5175\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.51177 to 0.51750, saving model to weights1.hdf5\n",
      "Epoch 6/10\n",
      " - 18s - loss: 0.0403 - accuracy: 0.9895 - f1: 0.5963 - val_loss: 0.2822 - val_accuracy: 0.9387 - val_f1: 0.5213\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.51750 to 0.52131, saving model to weights1.hdf5\n",
      "Epoch 7/10\n",
      " - 19s - loss: 0.0422 - accuracy: 0.9917 - f1: 0.5990 - val_loss: 0.3234 - val_accuracy: 0.9453 - val_f1: 0.5255\n",
      "\n",
      "Epoch 00007: val_f1 improved from 0.52131 to 0.52552, saving model to weights1.hdf5\n",
      "Epoch 8/10\n",
      " - 19s - loss: 0.0287 - accuracy: 0.9928 - f1: 0.6140 - val_loss: 0.3106 - val_accuracy: 0.9453 - val_f1: 0.5258\n",
      "\n",
      "Epoch 00008: val_f1 improved from 0.52552 to 0.52575, saving model to weights1.hdf5\n",
      "Epoch 9/10\n",
      " - 19s - loss: 0.0226 - accuracy: 0.9934 - f1: 0.6134 - val_loss: 0.3650 - val_accuracy: 0.9475 - val_f1: 0.5324\n",
      "\n",
      "Epoch 00009: val_f1 improved from 0.52575 to 0.53241, saving model to weights1.hdf5\n",
      "Epoch 10/10\n",
      " - 18s - loss: 0.0219 - accuracy: 0.9967 - f1: 0.6236 - val_loss: 0.3571 - val_accuracy: 0.9475 - val_f1: 0.5326\n",
      "\n",
      "Epoch 00010: val_f1 improved from 0.53241 to 0.53264, saving model to weights1.hdf5\n",
      "Iteration 2\n",
      "(1816, 100) (1816, 5) (456, 100) (456, 5)\n",
      "Train on 1816 samples, validate on 456 samples\n",
      "Epoch 1/10\n",
      " - 20s - loss: 0.4906 - accuracy: 0.8436 - f1: 0.3753 - val_loss: 0.0726 - val_accuracy: 0.9890 - val_f1: 0.5581\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.55810, saving model to weights2.hdf5\n",
      "Epoch 2/10\n",
      " - 19s - loss: 0.1338 - accuracy: 0.9719 - f1: 0.5692 - val_loss: 0.0548 - val_accuracy: 0.9890 - val_f1: 0.5581\n",
      "\n",
      "Epoch 00002: val_f1 did not improve from 0.55810\n",
      "Epoch 3/10\n",
      " - 18s - loss: 0.1187 - accuracy: 0.9730 - f1: 0.5700 - val_loss: 0.0480 - val_accuracy: 0.9890 - val_f1: 0.5584\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.55810 to 0.55843, saving model to weights2.hdf5\n",
      "Epoch 4/10\n",
      " - 18s - loss: 0.0983 - accuracy: 0.9752 - f1: 0.5806 - val_loss: 0.0296 - val_accuracy: 0.9890 - val_f1: 0.5584\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.55843\n",
      "Epoch 5/10\n",
      " - 18s - loss: 0.0853 - accuracy: 0.9785 - f1: 0.5792 - val_loss: 0.0210 - val_accuracy: 0.9890 - val_f1: 0.5600\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.55843 to 0.56000, saving model to weights2.hdf5\n",
      "Epoch 6/10\n",
      " - 18s - loss: 0.0702 - accuracy: 0.9796 - f1: 0.5825 - val_loss: 0.0172 - val_accuracy: 0.9890 - val_f1: 0.5575\n",
      "\n",
      "Epoch 00006: val_f1 did not improve from 0.56000\n",
      "Epoch 7/10\n",
      " - 18s - loss: 0.0785 - accuracy: 0.9752 - f1: 0.5814 - val_loss: 0.0224 - val_accuracy: 0.9890 - val_f1: 0.5581\n",
      "\n",
      "Epoch 00007: val_f1 did not improve from 0.56000\n",
      "Epoch 8/10\n",
      " - 18s - loss: 0.0637 - accuracy: 0.9802 - f1: 0.5851 - val_loss: 0.0166 - val_accuracy: 0.9934 - val_f1: 0.5677\n",
      "\n",
      "Epoch 00008: val_f1 improved from 0.56000 to 0.56768, saving model to weights2.hdf5\n",
      "Epoch 9/10\n",
      " - 18s - loss: 0.0541 - accuracy: 0.9862 - f1: 0.5984 - val_loss: 0.0110 - val_accuracy: 0.9934 - val_f1: 0.5677\n",
      "\n",
      "Epoch 00009: val_f1 did not improve from 0.56768\n",
      "Epoch 10/10\n",
      " - 18s - loss: 0.0459 - accuracy: 0.9873 - f1: 0.6059 - val_loss: 0.0036 - val_accuracy: 1.0000 - val_f1: 0.5867\n",
      "\n",
      "Epoch 00010: val_f1 improved from 0.56768 to 0.58667, saving model to weights2.hdf5\n",
      "Iteration 3\n",
      "(1818, 100) (1818, 5) (454, 100) (454, 5)\n",
      "Train on 1818 samples, validate on 454 samples\n",
      "Epoch 1/10\n",
      " - 21s - loss: 0.4703 - accuracy: 0.8608 - f1: 0.3901 - val_loss: 0.0742 - val_accuracy: 0.9890 - val_f1: 0.5297\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.52968, saving model to weights3.hdf5\n",
      "Epoch 2/10\n",
      " - 20s - loss: 0.1251 - accuracy: 0.9719 - f1: 0.5664 - val_loss: 0.0522 - val_accuracy: 0.9890 - val_f1: 0.5302\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.52968 to 0.53021, saving model to weights3.hdf5\n",
      "Epoch 3/10\n",
      " - 21s - loss: 0.1082 - accuracy: 0.9730 - f1: 0.5724 - val_loss: 0.0361 - val_accuracy: 0.9890 - val_f1: 0.5302\n",
      "\n",
      "Epoch 00003: val_f1 did not improve from 0.53021\n",
      "Epoch 4/10\n",
      " - 21s - loss: 0.0823 - accuracy: 0.9769 - f1: 0.5654 - val_loss: 0.0359 - val_accuracy: 0.9890 - val_f1: 0.5297\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.53021\n",
      "Epoch 5/10\n",
      " - 20s - loss: 0.0775 - accuracy: 0.9758 - f1: 0.5727 - val_loss: 0.0313 - val_accuracy: 0.9912 - val_f1: 0.5391\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.53021 to 0.53910, saving model to weights3.hdf5\n",
      "Epoch 6/10\n",
      " - 20s - loss: 0.0671 - accuracy: 0.9807 - f1: 0.5812 - val_loss: 0.0275 - val_accuracy: 0.9912 - val_f1: 0.5397\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.53910 to 0.53967, saving model to weights3.hdf5\n",
      "Epoch 7/10\n",
      " - 20s - loss: 0.0565 - accuracy: 0.9835 - f1: 0.5948 - val_loss: 0.0227 - val_accuracy: 0.9890 - val_f1: 0.5314\n",
      "\n",
      "Epoch 00007: val_f1 did not improve from 0.53967\n",
      "Epoch 8/10\n",
      " - 20s - loss: 0.0594 - accuracy: 0.9835 - f1: 0.5925 - val_loss: 0.0131 - val_accuracy: 0.9956 - val_f1: 0.5543\n",
      "\n",
      "Epoch 00008: val_f1 improved from 0.53967 to 0.55434, saving model to weights3.hdf5\n",
      "Epoch 9/10\n",
      " - 20s - loss: 0.0537 - accuracy: 0.9846 - f1: 0.6029 - val_loss: 0.0126 - val_accuracy: 0.9956 - val_f1: 0.5543\n",
      "\n",
      "Epoch 00009: val_f1 did not improve from 0.55434\n",
      "Epoch 10/10\n",
      " - 20s - loss: 0.0533 - accuracy: 0.9851 - f1: 0.6034 - val_loss: 0.0160 - val_accuracy: 0.9978 - val_f1: 0.5499\n",
      "\n",
      "Epoch 00010: val_f1 did not improve from 0.55434\n",
      "Iteration 4\n",
      "(1819, 100) (1819, 5) (453, 100) (453, 5)\n",
      "Train on 1819 samples, validate on 453 samples\n",
      "Epoch 1/10\n",
      " - 20s - loss: 0.4881 - accuracy: 0.8521 - f1: 0.3800 - val_loss: 0.0605 - val_accuracy: 0.9912 - val_f1: 0.5139\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.51388, saving model to weights4.hdf5\n",
      "Epoch 2/10\n",
      " - 20s - loss: 0.1296 - accuracy: 0.9742 - f1: 0.5728 - val_loss: 0.0375 - val_accuracy: 0.9912 - val_f1: 0.5139\n",
      "\n",
      "Epoch 00002: val_f1 did not improve from 0.51388\n",
      "Epoch 3/10\n",
      " - 20s - loss: 0.1021 - accuracy: 0.9725 - f1: 0.5703 - val_loss: 0.0294 - val_accuracy: 0.9912 - val_f1: 0.5169\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.51388 to 0.51693, saving model to weights4.hdf5\n",
      "Epoch 4/10\n",
      " - 20s - loss: 0.0937 - accuracy: 0.9742 - f1: 0.5639 - val_loss: 0.0281 - val_accuracy: 0.9912 - val_f1: 0.5139\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.51693\n",
      "Epoch 5/10\n",
      " - 22s - loss: 0.0810 - accuracy: 0.9786 - f1: 0.5826 - val_loss: 0.0226 - val_accuracy: 0.9912 - val_f1: 0.5139\n",
      "\n",
      "Epoch 00005: val_f1 did not improve from 0.51693\n",
      "Epoch 6/10\n",
      " - 20s - loss: 0.0669 - accuracy: 0.9808 - f1: 0.5866 - val_loss: 0.0236 - val_accuracy: 0.9912 - val_f1: 0.5139\n",
      "\n",
      "Epoch 00006: val_f1 did not improve from 0.51693\n",
      "Iteration 5\n",
      "(1820, 100) (1820, 5) (452, 100) (452, 5)\n",
      "Train on 1820 samples, validate on 452 samples\n",
      "Epoch 1/10\n",
      " - 19s - loss: 0.4873 - accuracy: 0.8505 - f1: 0.3757 - val_loss: 0.1723 - val_accuracy: 0.9823 - val_f1: 0.4853\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.48525, saving model to weights5.hdf5\n",
      "Epoch 2/10\n",
      " - 20s - loss: 0.1066 - accuracy: 0.9742 - f1: 0.5769 - val_loss: 0.1735 - val_accuracy: 0.9668 - val_f1: 0.4887\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.48525 to 0.48875, saving model to weights5.hdf5\n",
      "Epoch 3/10\n",
      " - 19s - loss: 0.0870 - accuracy: 0.9731 - f1: 0.5791 - val_loss: 0.1799 - val_accuracy: 0.9558 - val_f1: 0.4989\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.48875 to 0.49889, saving model to weights5.hdf5\n",
      "Epoch 4/10\n",
      " - 19s - loss: 0.0719 - accuracy: 0.9797 - f1: 0.5830 - val_loss: 0.1393 - val_accuracy: 0.9823 - val_f1: 0.4963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.49889\n",
      "Epoch 5/10\n",
      " - 19s - loss: 0.0621 - accuracy: 0.9813 - f1: 0.5735 - val_loss: 0.1567 - val_accuracy: 0.9690 - val_f1: 0.4912\n",
      "\n",
      "Epoch 00005: val_f1 did not improve from 0.49889\n",
      "Epoch 6/10\n",
      " - 19s - loss: 0.0482 - accuracy: 0.9846 - f1: 0.6027 - val_loss: 0.1521 - val_accuracy: 0.9646 - val_f1: 0.4883\n",
      "\n",
      "Epoch 00006: val_f1 did not improve from 0.49889\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "cross_val_predict_nn = np.zeros(X.shape[0])\n",
    "all_history = {}\n",
    "\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5).split(X,data.overall.values):\n",
    "    iter += 1\n",
    "    \n",
    "    print (\"Iteration {}\".format(iter))\n",
    "    \n",
    "    train_x = X[train_index]\n",
    "    train_y = y[train_index]\n",
    "    val_x = X[test_index]\n",
    "    val_y = y[test_index]\n",
    "    \n",
    "    print (train_x.shape, train_y.shape, val_x.shape, val_y.shape)\n",
    "    model = get_model()\n",
    "    early = EarlyStopping(monitor='val_f1', min_delta=0, patience=3, verbose=0, mode='max', baseline=None, restore_best_weights=False)\n",
    "    lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.000001)\n",
    "    checkpointer = ModelCheckpoint(monitor='val_f1',filepath='weights{}.hdf5'.format(iter), mode='max',verbose=1, save_best_only=True)\n",
    "    \n",
    "    history = model.fit(train_x, train_y, epochs = n_epochs, batch_size=batch_size, verbose = 2, validation_data=(val_x,val_y), callbacks=[early,lr,checkpointer])\n",
    "    all_history[iter] = history\n",
    "    \n",
    "    model = load_model('weights1.hdf5',custom_objects={'f1':f1})\n",
    "    \n",
    "    cross_val_predict_nn[test_index] = model.predict(val_x).argmax(axis=1) + np.ones(val_x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='evlstm'></a>\n",
    "\n",
    "#### Evaluating LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980193661971831\n",
      "0.8510651399577986\n",
      "[[   6    0    2    0    1]\n",
      " [   0    6    0    0    7]\n",
      " [   0    0  412    0    9]\n",
      " [   1    0    0  207   14]\n",
      " [   1    0    1    9 1596]]\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(data.overall,cross_val_predict_nn))\n",
    "print (f1_score(data.overall,cross_val_predict_nn,average='macro'))\n",
    "print (confusion_matrix(data.overall,cross_val_predict_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In just 10 epochs, we can see a drastic improvement over previous models. One can change the type of RNN cell, increase model depth, number of cell, even different architecture. Before finishing off our tutorial, let us see how the model optimized the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne1oa5rAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(all_history[1].history['loss'])\n",
    "plt.plot(all_history[1].history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMi6FhYiIjEthISIi41JYiIjIuP4/7QZFPDLOVhcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_history[1].history['f1'])\n",
    "plt.plot(all_history[1].history['val_f1'])\n",
    "plt.title('model F1')\n",
    "plt.ylabel('F1')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLEREZFT/H8HeLmRbQnK7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_history[1].history['accuracy'])\n",
    "plt.plot(all_history[1].history['val_accuracy'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch LSTM\n",
    "\n",
    "Same exercise we do using Pytorch library. Pytorch is developed by Facebook and has recently surpassed the popularity of tensorflow due to its design and efficiency. This subsection can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x261aa45c990>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_matrix, seq_len, hidden_size, n_layers, num_class, non_trainable=True):\n",
    "        super().__init__()\n",
    "        vocab_size = embedding_matrix.shape[0]\n",
    "        embed_dim = embedding_matrix.shape[1]\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size,embed_dim)\n",
    "        self.embedding.load_state_dict({'weight': torch.LongTensor(embedding_matrix)})\n",
    "        if non_trainable:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "            \n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size*seq_len, num_class)\n",
    "\n",
    "    def forward(self, text, hidden):\n",
    "        batch_size = text.shape[0]\n",
    "        out, hidden = self.lstm(self.embedding(text),hidden)\n",
    "        out = out.contiguous().view(batch_size,-1)\n",
    "        return self.fc(out), hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize Hidden STATE\"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_size).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_size).zero_().to(device))\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of LSTMClassifier(\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (embedding): Embedding(1064, 100)\n",
      "  (lstm): LSTM(100, 196, batch_first=True)\n",
      "  (fc): Linear(in_features=19600, out_features=5, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(embedding_matrix,max_len,lstm_out,1,n_output)\n",
    "print (model.parameters)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* Iteration 1 **************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asengup6\\softwares\\anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\asengup6\\softwares\\anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 0.195, train acc 0.950, train f1 0.850, val loss 0.222, val acc 0.943, val f1 0.850\n",
      "\n",
      "saving new checkpoint in model1_torch.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asengup6\\softwares\\anaconda\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LSTMClassifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 0.035, train acc 0.993, train f1 0.954, val loss 0.246, val acc 0.921, val f1 0.706\n",
      "\n",
      "Epoch 2: train loss 0.029, train acc 0.993, train f1 0.951, val loss 0.236, val acc 0.945, val f1 0.854\n",
      "\n",
      "saving new checkpoint in model1_torch.hdf5\n",
      "Epoch 3: train loss 0.029, train acc 0.993, train f1 0.958, val loss 0.218, val acc 0.945, val f1 0.882\n",
      "\n",
      "saving new checkpoint in model1_torch.hdf5\n",
      "Epoch 4: train loss 0.024, train acc 0.993, train f1 0.953, val loss 0.236, val acc 0.945, val f1 0.838\n",
      "\n",
      "Epoch 5: train loss 0.021, train acc 0.994, train f1 0.965, val loss 0.235, val acc 0.945, val f1 0.876\n",
      "\n",
      "saving new checkpoint in model1_torch.hdf5\n",
      "Epoch 6: train loss 0.020, train acc 0.994, train f1 0.965, val loss 0.260, val acc 0.945, val f1 0.863\n",
      "\n",
      "Epoch 7: train loss 0.016, train acc 0.996, train f1 0.978, val loss 0.311, val acc 0.945, val f1 0.883\n",
      "\n",
      "saving new checkpoint in model1_torch.hdf5\n",
      "Epoch 8: train loss 0.014, train acc 0.997, train f1 0.984, val loss 0.277, val acc 0.945, val f1 0.826\n",
      "\n",
      "Epoch 9: train loss 0.011, train acc 0.996, train f1 0.979, val loss 0.315, val acc 0.947, val f1 0.863\n",
      "\n",
      "saving new checkpoint in model1_torch.hdf5\n",
      "******************* Iteration 2 **************\n",
      "\n",
      "Epoch 0: train loss 0.241, train acc 0.933, train f1 0.825, val loss 0.025, val acc 0.989, val f1 0.931\n",
      "\n",
      "saving new checkpoint in model2_torch.hdf5\n",
      "Epoch 1: train loss 0.080, train acc 0.980, train f1 0.919, val loss 0.005, val acc 1.000, val f1 1.000\n",
      "\n",
      "saving new checkpoint in model2_torch.hdf5\n",
      "Epoch 2: train loss 0.061, train acc 0.982, train f1 0.920, val loss 0.010, val acc 0.993, val f1 0.952\n",
      "\n",
      "Epoch 3: train loss 0.057, train acc 0.985, train f1 0.928, val loss 0.005, val acc 1.000, val f1 1.000\n",
      "\n",
      "saving new checkpoint in model2_torch.hdf5\n",
      "Epoch 4: train loss 0.048, train acc 0.987, train f1 0.943, val loss 0.001, val acc 1.000, val f1 1.000\n",
      "\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 5: train loss 0.041, train acc 0.990, train f1 0.958, val loss 0.000, val acc 1.000, val f1 1.000\n",
      "\n",
      "Epoch 6: train loss 0.033, train acc 0.991, train f1 0.959, val loss 0.000, val acc 1.000, val f1 1.000\n",
      "\n",
      "Epoch 7: train loss 0.032, train acc 0.992, train f1 0.962, val loss 0.000, val acc 1.000, val f1 1.000\n",
      "\n",
      "Epoch 8: train loss 0.031, train acc 0.992, train f1 0.962, val loss 0.000, val acc 1.000, val f1 1.000\n",
      "\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 9: train loss 0.030, train acc 0.992, train f1 0.969, val loss 0.000, val acc 1.000, val f1 1.000\n",
      "\n",
      "******************* Iteration 3 **************\n",
      "\n",
      "Epoch 0: train loss 0.246, train acc 0.927, train f1 0.809, val loss 0.033, val acc 0.989, val f1 0.928\n",
      "\n",
      "saving new checkpoint in model3_torch.hdf5\n",
      "Epoch 1: train loss 0.073, train acc 0.981, train f1 0.935, val loss 0.024, val acc 0.993, val f1 0.985\n",
      "\n",
      "saving new checkpoint in model3_torch.hdf5\n",
      "Epoch 2: train loss 0.059, train acc 0.983, train f1 0.938, val loss 0.020, val acc 0.993, val f1 0.943\n",
      "\n",
      "Epoch 3: train loss 0.055, train acc 0.987, train f1 0.955, val loss 0.018, val acc 0.993, val f1 0.933\n",
      "\n",
      "Epoch 4: train loss 0.044, train acc 0.990, train f1 0.955, val loss 0.016, val acc 0.993, val f1 0.958\n",
      "\n",
      "saving new checkpoint in model3_torch.hdf5\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 5: train loss 0.038, train acc 0.990, train f1 0.962, val loss 0.016, val acc 0.996, val f1 0.969\n",
      "\n",
      "saving new checkpoint in model3_torch.hdf5\n",
      "Epoch 6: train loss 0.035, train acc 0.991, train f1 0.964, val loss 0.017, val acc 0.996, val f1 0.960\n",
      "\n",
      "Epoch 7: train loss 0.032, train acc 0.992, train f1 0.963, val loss 0.016, val acc 0.996, val f1 0.969\n",
      "\n",
      "saving new checkpoint in model3_torch.hdf5\n",
      "Epoch 8: train loss 0.031, train acc 0.992, train f1 0.970, val loss 0.016, val acc 0.996, val f1 0.966\n",
      "\n",
      "Epoch 9: train loss 0.030, train acc 0.992, train f1 0.970, val loss 0.016, val acc 0.996, val f1 0.991\n",
      "\n",
      "saving new checkpoint in model3_torch.hdf5\n",
      "******************* Iteration 4 **************\n",
      "\n",
      "Epoch 0: train loss 0.242, train acc 0.931, train f1 0.808, val loss 0.040, val acc 0.991, val f1 0.948\n",
      "\n",
      "saving new checkpoint in model4_torch.hdf5\n",
      "Epoch 1: train loss 0.073, train acc 0.980, train f1 0.917, val loss 0.037, val acc 0.991, val f1 0.939\n",
      "\n",
      "Epoch 2: train loss 0.058, train acc 0.984, train f1 0.943, val loss 0.033, val acc 0.991, val f1 0.932\n",
      "\n",
      "Epoch 3: train loss 0.050, train acc 0.986, train f1 0.960, val loss 0.031, val acc 0.991, val f1 0.939\n",
      "\n",
      "saving new checkpoint in model4_torch.hdf5\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 4: train loss 0.038, train acc 0.990, train f1 0.957, val loss 0.035, val acc 0.991, val f1 0.931\n",
      "\n",
      "Epoch 5: train loss 0.034, train acc 0.990, train f1 0.969, val loss 0.032, val acc 0.991, val f1 0.939\n",
      "\n",
      "saving new checkpoint in model4_torch.hdf5\n",
      "Epoch 6: train loss 0.032, train acc 0.992, train f1 0.967, val loss 0.031, val acc 0.991, val f1 0.939\n",
      "\n",
      "Epoch 7: train loss 0.031, train acc 0.992, train f1 0.969, val loss 0.028, val acc 0.993, val f1 0.952\n",
      "\n",
      "saving new checkpoint in model4_torch.hdf5\n",
      "Epoch 8: train loss 0.029, train acc 0.992, train f1 0.970, val loss 0.028, val acc 0.993, val f1 0.949\n",
      "\n",
      "Epoch 9: train loss 0.028, train acc 0.993, train f1 0.971, val loss 0.027, val acc 0.993, val f1 0.960\n",
      "\n",
      "saving new checkpoint in model4_torch.hdf5\n",
      "******************* Iteration 5 **************\n",
      "\n",
      "Epoch 0: train loss 0.216, train acc 0.933, train f1 0.808, val loss 0.083, val acc 0.987, val f1 0.920\n",
      "\n",
      "saving new checkpoint in model5_torch.hdf5\n",
      "Epoch 1: train loss 0.057, train acc 0.982, train f1 0.910, val loss 0.117, val acc 0.985, val f1 0.932\n",
      "\n",
      "saving new checkpoint in model5_torch.hdf5\n",
      "Epoch 2: train loss 0.039, train acc 0.988, train f1 0.943, val loss 0.138, val acc 0.971, val f1 0.879\n",
      "\n",
      "Epoch 3: train loss 0.032, train acc 0.990, train f1 0.955, val loss 0.119, val acc 0.982, val f1 0.924\n",
      "\n",
      "saving new checkpoint in model5_torch.hdf5\n",
      "Epoch 4: train loss 0.025, train acc 0.993, train f1 0.968, val loss 0.137, val acc 0.980, val f1 0.923\n",
      "\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 5: train loss 0.022, train acc 0.993, train f1 0.966, val loss 0.192, val acc 0.962, val f1 0.830\n",
      "\n",
      "Epoch 6: train loss 0.018, train acc 0.994, train f1 0.973, val loss 0.163, val acc 0.971, val f1 0.906\n",
      "\n",
      "saving new checkpoint in model5_torch.hdf5\n",
      "Epoch 7: train loss 0.017, train acc 0.994, train f1 0.977, val loss 0.165, val acc 0.969, val f1 0.916\n",
      "\n",
      "saving new checkpoint in model5_torch.hdf5\n",
      "Epoch 8: train loss 0.017, train acc 0.994, train f1 0.973, val loss 0.172, val acc 0.967, val f1 0.894\n",
      "\n",
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 9: train loss 0.017, train acc 0.994, train f1 0.975, val loss 0.179, val acc 0.967, val f1 0.902\n",
      "\n",
      "saving new checkpoint in model5_torch.hdf5\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "cross_val_predict_nn = np.zeros(X.shape[0])\n",
    "all_history = {}\n",
    "\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5).split(X,data.overall.values):\n",
    "    iter += 1\n",
    "    \n",
    "    all_history[iter] = {}\n",
    "    \n",
    "    print (\"******************* Iteration {} **************\".format(iter))\n",
    "    print ()\n",
    "    \n",
    "    train_x = X[train_index]\n",
    "    train_y = y[train_index]\n",
    "    val_x = X[test_index]\n",
    "    val_y = y[test_index]\n",
    "    \n",
    "    train_data = TensorDataset(torch.LongTensor(train_x), torch.LongTensor(train_y))\n",
    "    val_data = TensorDataset(torch.LongTensor(val_x), torch.LongTensor(val_y))\n",
    "\n",
    "    #dataloader\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    \n",
    "    model = LSTMClassifier(embedding_matrix,max_len,lstm_out,n_layers, n_output)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True, min_lr=.000001,mode='max')\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    all_history[iter][-1] = {'epoch_train_loss':0,'epoch_train_acc':0,'epoch_train_f1':0,\n",
    "                               'epoch_val_loss':0,'epoch_val_acc':0,'epoch_val_f1':0}\n",
    "    \n",
    "    # train for some number of epochs\n",
    "    for e in range(n_epochs):\n",
    "        \n",
    "        epoch_train_loss = 0\n",
    "        epoch_train_acc = 0\n",
    "        epoch_train_f1 = 0\n",
    "        epoch_val_loss = 0\n",
    "        epoch_val_acc = 0\n",
    "        epoch_val_f1 = 0\n",
    "        \n",
    "        running_train_loss = 0.0\n",
    "        running_train_corrects = 0\n",
    "        running_train_f1 = 0\n",
    "        counter = 0\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        # batch loop\n",
    "        for inputs, labels in train_loader:\n",
    "            counter += 1\n",
    "\n",
    "            # initialize hidden state\n",
    "            h = model.init_hidden(inputs.shape[0])\n",
    "        \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # get the output from the model\n",
    "            output, h = model(inputs, h)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "            #loss = criterion(output.squeeze(), labels.long())\n",
    "            loss = criterion(output, torch.max(labels, 1)[1])\n",
    "            \n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(output, 1)\n",
    "            \n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "            running_train_corrects += torch.sum(preds == torch.argmax(labels.data,1))\n",
    "            running_train_f1 += f1_score(np.array(labels.data.to('cpu')).argmax(1), np.array(preds.data.to('cpu')), average='macro')\n",
    "            \n",
    "        epoch_train_loss = running_train_loss / train_x.shape[0]\n",
    "        epoch_train_acc = running_train_corrects.double() / train_x.shape[0]\n",
    "        epoch_train_f1 = running_train_f1 / counter\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        running_val_loss = 0.0\n",
    "        running_val_corrects = 0\n",
    "        running_val_f1 = 0\n",
    "        counter = 0\n",
    "\n",
    "        # batch loop\n",
    "        for inputs, labels in val_loader:\n",
    "            counter += 1\n",
    "\n",
    "            # initialize hidden state\n",
    "            h = model.init_hidden(inputs.shape[0])\n",
    "        \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            # h = tuple([each.data for each in h])\n",
    "\n",
    "            # get the output from the model\n",
    "            output, h = model(inputs, h)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "            #loss = criterion(output.squeeze(), labels.long())\n",
    "            loss = criterion(output, torch.max(labels, 1)[1])\n",
    "            \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            running_val_loss += loss.item() * inputs.size(0)\n",
    "            running_val_corrects += torch.sum(preds == torch.argmax(labels.data,1))\n",
    "            running_val_f1 += f1_score(np.array(labels.data.to('cpu')).argmax(1), np.array(preds.data.to('cpu')), average='macro')\n",
    "\n",
    "\n",
    "        epoch_val_loss = running_val_loss / val_x.shape[0]\n",
    "        epoch_val_acc = running_val_corrects.double() / val_x.shape[0]\n",
    "        epoch_val_f1 = running_val_f1 / counter\n",
    "    \n",
    "        all_history[iter][e] = {'epoch_train_loss':epoch_train_loss,'epoch_train_acc':epoch_train_acc,'epoch_train_f1':epoch_train_f1,\n",
    "                               'epoch_val_loss':epoch_val_loss,'epoch_val_acc':epoch_val_acc,'epoch_val_f1':epoch_val_f1}\n",
    "        \n",
    "        scheduler.step(epoch_val_f1)\n",
    "        \n",
    "        print (\"Epoch {}: train loss {:.3f}, train acc {:.3f}, train f1 {:.3f}, val loss {:.3f}, val acc {:.3f}, val f1 {:.3f}\".format(e, epoch_train_loss,\n",
    "                epoch_train_acc, epoch_train_f1, epoch_val_loss, epoch_val_acc, epoch_val_f1))\n",
    "        print()\n",
    "        \n",
    "        if epoch_val_f1 > all_history[iter][e-1]['epoch_val_f1']:\n",
    "            torch.save(model,\"model{}_torch.hdf5\".format(iter))\n",
    "            print (\"saving new checkpoint in model{}_torch.hdf5\".format(iter))\n",
    "    output, _ = model(torch.LongTensor(val_x),model.init_hidden(val_x.shape[0]))\n",
    "    cross_val_predict_nn[test_index] = np.array(output.data.to('cpu')).argmax(axis=1) + np.ones(val_x.shape[0])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9806338028169014\n",
      "0.8647741291251725\n",
      "[[   7    0    0    0    2]\n",
      " [   0    5    0    0    8]\n",
      " [   0    0  412    0    9]\n",
      " [   0    0    0  206   16]\n",
      " [   0    1    2    6 1598]]\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(data.overall,cross_val_predict_nn))\n",
    "print (f1_score(data.overall,cross_val_predict_nn,average='macro'))\n",
    "print (confusion_matrix(data.overall,cross_val_predict_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
